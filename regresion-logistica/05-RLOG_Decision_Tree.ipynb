{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Gráficos\n",
    "# ------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelado y evaluación\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score , cohen_kappa_score, roc_curve,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Configuración warnings\n",
    "# ------------------------------------------------------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair Programming Decision Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ana G y Ana C"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora hemos ajustado el modelo usando una Regresión Logística, pero como hemos aprendido, podemos usar el Decision Tree en este tipo de problemas. \n",
    "\n",
    "Los objetivos de este pair programming :\n",
    "\n",
    "- Ajustad un modelo de Decision Tree a nuestros datos.\n",
    "-Calculad las métricas a nuestro nuevo modelo.\n",
    "-Comparad las métricas con el modelo hecho hasta ahora. ¿Cuál es mejor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cod_noest = pd.read_pickle(\"../data-log/02-df_codifcadas_no_estandarizadas.pickle\")\n",
    "df_cod_noest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cod_esta = pd.read_pickle(\"../data-log/02-df_estandarizadas_codificadas.pickle\")\n",
    "df_cod_esta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal = pd.read_pickle(\"../data-log/02-bal_est_cod.pickle\")\n",
    "df_bal.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Datos  NO estandarizadas, no balanceado,codificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos en X e y\n",
    "X1 = df_cod_noest.drop(\"TenYearCHD\", axis = 1)\n",
    "y1 = df_cod_noest[\"TenYearCHD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos en train y test\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos el objeto del modelo, al igual que hacíamos en la regresión lineal\n",
    "arbol = DecisionTreeClassifier(random_state =0)\n",
    "# ajustamos el modelo, igual que en la regresión lienal. \n",
    "arbol.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "tree.plot_tree(arbol, feature_names = x_train1.columns, filled = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max features. Como vemos, debemos poner en nuestro modelo una profudidad máxima de 4. \n",
    "max_features = np.sqrt(len(x_train1.columns))\n",
    "max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max depth\n",
    "print(arbol.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos las predicciones sobre los dos set de datos el X_test y el X_train\n",
    "y_pred_test_esta = arbol.predict(x_test1)\n",
    "y_pred_train_esta = arbol.predict(x_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas(clases_reales_test, clases_predichas_test, clases_reales_train, clases_predichas_train, modelo):\n",
    "    \n",
    "    # para el test\n",
    "    accuracy_test = accuracy_score(clases_reales_test, clases_predichas_test)\n",
    "    precision_test = precision_score(clases_reales_test, clases_predichas_test)\n",
    "    recall_test = recall_score(clases_reales_test, clases_predichas_test)\n",
    "    f1_test = f1_score(clases_reales_test, clases_predichas_test)\n",
    "    kappa_test = cohen_kappa_score(clases_reales_test, clases_predichas_test)\n",
    "\n",
    "    # para el train\n",
    "    accuracy_train = accuracy_score(clases_reales_train, clases_predichas_train)\n",
    "    precision_train = precision_score(clases_reales_train, clases_predichas_train)\n",
    "    recall_train = recall_score(clases_reales_train, clases_predichas_train)\n",
    "    f1_train = f1_score(clases_reales_train, clases_predichas_train)\n",
    "    kappa_train = cohen_kappa_score(clases_reales_train, clases_predichas_train)\n",
    "    \n",
    "\n",
    "    \n",
    "    df = pd.DataFrame({\"accuracy\": [accuracy_test, accuracy_train], \n",
    "                       \"precision\": [precision_test, precision_train],\n",
    "                       \"recall\": [recall_test, recall_train], \n",
    "                       \"f1\": [f1_test, f1_train],\n",
    "                       \"kapppa\": [kappa_test, kappa_train],\n",
    "                       \"set\": [\"test\", \"train\"]})\n",
    "    \n",
    "    df[\"modelo\"] = modelo\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacamos las métricas para ver si hay overfitting o unerfitting, para modificar la profundidad en función de estos resultados\n",
    "\n",
    "dt_results1 = metricas(y_test1, y_pred_test_esta, y_train1, y_pred_train_esta, \"Decission Tree NO Esta I\")\n",
    "dt_results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo primero que tenemos que hacer es definir un diccionario con los hiperparámetros que queremos modificar y los valores que queremos \n",
    "\n",
    "param = {\"max_depth\": [2,4, 6, 10, 12, 14], # teniendo en cuenta que teníamos overfitting tendremos que reducir la profundidad del modelo, la nuestra anterior era de 17. Bajaremos mucho este valor ya que teníamos un overfitting muy claro\n",
    "        \"max_features\": [1,2,3,4],# calculamos en celdas anteriores, probaremos a hacer el modelo como una variable, 2, 3 y 4. Ponemos como límite el 4 ya que es el resultado de la raiz cuadrada. \n",
    "        # estos dos hiperparámetros son más difíciles de definir, pero usualmente se suelen elegir los siguientes valores\n",
    "        \"min_samples_split\": [10, 50, 100],\n",
    "        \"min_samples_leaf\": [10,50,100]} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# una vez creado el diccionario iniciaremos el modelo con GridSearch\n",
    "\n",
    "gs = GridSearchCV(\n",
    "            estimator=DecisionTreeClassifier(random_state= 42), # tipo de modelo que queremos hacer\n",
    "            param_grid= param, # que hiperparámetros queremos que testee\n",
    "            cv=10, # crossvalidation que aprendimos en la lección de regresión lineal intro. \n",
    "            verbose=-1) # para que no nos printee ningún mensaje en pantalla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustamos el modelo que acabamos de definir en el GridSearch\n",
    "\n",
    "gs.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# este método nos esta diciendo que el mejor modelo es aquel que tiene una profundidad de 6, que usa 4 variables predictoras para construir el modelo y que tiene  un min_samples_leaf y un min_samples_split de 10. \n",
    "mejor_modelo = gs.best_estimator_\n",
    "mejor_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veamos ahora que pinta tiene nuestro árbol\n",
    "\n",
    "fig = plt.figure(figsize=(40, 20))\n",
    "tree.plot_tree(mejor_modelo, feature_names=x_train1.columns, filled=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_esta2 = mejor_modelo.predict(x_test1)\n",
    "y_pred_train_esta2 = mejor_modelo.predict(x_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_results2 = metricas(y_test1, y_pred_test_esta2, y_train1,  y_pred_train_esta2, \"DecisionTree NO Esta II\")\n",
    "dt_results2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos  a juntar los dataframes de los resultados de los modelos para poder compararlos mejor\n",
    "\n",
    "df_decision_results = pd.concat([dt_results1, dt_results2], axis = 0)\n",
    "df_decision_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si recodáis, en la clase de métricas guardamos en un csv los resultados de las métricas del modelo\n",
    "# vamos a cargar ese csv para comparar todos los modelos que hemos hecho, y comparar cuál de ellos es el mejor\n",
    "\n",
    "df_logistic_results = pd.read_pickle(\"../data-log/04-df_metricas_resultados.pickle\")\n",
    "df_logistic_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenamos todos los resultados\n",
    "\n",
    "df_DT_LR_results = pd.concat([df_logistic_results, df_decision_results], axis = 0).reset_index(drop=True)\n",
    "df_DT_LR_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizaremos si queremos borrar algun ode lso resultados\n",
    "# df_DT_LR_results.drop([0,1,4,5], axis = 0, inplace = True)\n",
    "# df_DT_LR_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pongamos un poco de color a nuestro dataframe para ver la comparación de los datos de una forma un poco más amigable. \n",
    "df_DT_LR_results.style.background_gradient(cmap='seismic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ademas vamos a guardar este dataframe en un csv para \n",
    "\n",
    "df_DT_LR_results.to_csv(\"../datos/06-resultados_DTNOEsta_LR_DT.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Estandarizadas y no balanceado,codificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos en X e y\n",
    "\n",
    "X2 = df_cod_esta.drop(\"TenYearCHD\", axis = 1)\n",
    "y2 = df_cod_esta[\"TenYearCHD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos en train y test\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos el objeto del modelo, al igual que hacíamos en la regresión lineal\n",
    "arbol = DecisionTreeClassifier(random_state =0)\n",
    "# ajustamos el modelo, igual que en la regresión lienal. \n",
    "arbol.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "tree.plot_tree(arbol, feature_names = x_train1.columns, filled = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max features. Como vemos, debemos poner en nuestro modelo una profudidad máxima de 4. \n",
    "max_features = np.sqrt(len(x_train2.columns))\n",
    "max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max depth\n",
    "print(arbol.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos las predicciones sobre los dos set de datos el X_test y el X_train\n",
    "y_pred_test_esta = arbol.predict(x_test2)\n",
    "y_pred_train_esta = arbol.predict(x_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacamos las métricas para ver si hay overfitting o unerfitting, para modificar la profundidad en función de estos resultados\n",
    "dt_results2 = metricas(y_test1, y_pred_test_esta, y_train1, y_pred_train_esta, \"Decission Tree Esta I\")\n",
    "dt_results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo primero que tenemos que hacer es definir un diccionario con los hiperparámetros que queremos modificar y los valores que queremos \n",
    "\n",
    "param2 = {\"max_depth\": [2,4, 6, 10, 12, 14], # teniendo en cuenta que teníamos overfitting tendremos que reducir la profundidad del modelo, la nuestra anterior era de 17. Bajaremos mucho este valor ya que teníamos un overfitting muy claro\n",
    "        \"max_features\": [1,2,3,4],# calculamos en celdas anteriores, probaremos a hacer el modelo como una variable, 2, 3 y 4. Ponemos como límite el 4 ya que es el resultado de la raiz cuadrada. \n",
    "        # estos dos hiperparámetros son más difíciles de definir, pero usualmente se suelen elegir los siguientes valores\n",
    "        \"min_samples_split\": [10, 50, 100],\n",
    "        \"min_samples_leaf\": [10,50,100]} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# una vez creado el diccionario iniciaremos el modelo con GridSearch\n",
    "\n",
    "gs2 = GridSearchCV(\n",
    "            estimator=DecisionTreeClassifier(random_state= 42), # tipo de modelo que queremos hacer\n",
    "            param_grid= param2, # que hiperparámetros queremos que testee\n",
    "            cv=10, # crossvalidation que aprendimos en la lección de regresión lineal intro. \n",
    "            verbose=-1) # para que no nos printee ningún mensaje en pantalla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustamos el modelo que acabamos de definir en el GridSearch\n",
    "\n",
    "gs2.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# este método nos esta diciendo que el mejor modelo es aquel que tiene una profundidad de 6, que usa 4 variables predictoras para construir el modelo y que tiene  un min_samples_leaf y un min_samples_split de 10. \n",
    "mejor_modelo2 = gs2.best_estimator_\n",
    "mejor_modelo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veamos ahora que pinta tiene nuestro árbol\n",
    "\n",
    "fig2 = plt.figure(figsize=(40, 20))\n",
    "tree.plot_tree(mejor_modelo2, feature_names=x_train2.columns, filled=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_esta3 = mejor_modelo2.predict(x_test2)\n",
    "y_pred_train_esta3 = mejor_modelo2.predict(x_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_results2 = metricas(y_test2, y_pred_test_esta2, y_train2,  y_pred_train_esta2, \"DecisionTree Esta II\")\n",
    "dt_results2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos  a juntar los dataframes de los resultados de los modelos para poder compararlos mejor\n",
    "\n",
    "df_decision_results = pd.concat([dt_results1, dt_results2], axis = 0)\n",
    "df_decision_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si recodáis, en la clase de métricas guardamos en un csv los resultados de las métricas del modelo\n",
    "# vamos a cargar ese csv para comparar todos los modelos que hemos hecho, y comparar cuál de ellos es el mejor\n",
    "\n",
    "df_logistic_results = pd.read_pickle(\"../data-log/04-df_metricas_resultados.pickle\")\n",
    "df_logistic_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenamos todos los resultados\n",
    "\n",
    "df_DT_LR_results = pd.concat([df_logistic_results, df_decision_results], axis = 0).reset_index(drop=True)\n",
    "df_DT_LR_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizaremos si queremos borrar algun ode lso resultados\n",
    "#df_DT_LR_results.drop([0,1,4,5], axis = 0, inplace = True)\n",
    "#df_DT_LR_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pongamos un poco de color a nuestro dataframe para ver la comparación de los datos de una forma un poco más amigable. \n",
    "df_DT_LR_results.style.background_gradient(cmap='seismic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ademas vamos a guardar este dataframe en un csv para \n",
    "\n",
    "df_DT_LR_results.to_csv(\"../datos/resultados_DT_est_LR_DT.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Balanceada, estandarizadas, codificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos en X e y\n",
    "\n",
    "X3 = df_bal.drop(\"TenYearCHD\", axis = 1)\n",
    "y3 = df_bal[\"TenYearCHD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos en train y test\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos el objeto del modelo, al igual que hacíamos en la regresión lineal\n",
    "arbol3 = DecisionTreeClassifier(random_state =0)\n",
    "\n",
    "# ajustamos el modelo, igual que en la regresión lienal. \n",
    "arbol3.fit(x_train3, y_train3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "tree.plot_tree(arbol3, feature_names = x_train3.columns, filled = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max features. Como vemos, debemos poner en nuestro modelo una profudidad máxima de 4. \n",
    "\n",
    "max_features3 = np.sqrt(len(x_train3.columns))\n",
    "max_features3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# max depth\n",
    "\n",
    "print(arbol3.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos las predicciones sobre los dos set de datos el X_test y el X_train\n",
    "y_pred_test_esta3 = arbol3.predict(x_test3)\n",
    "y_pred_train_esta3 = arbol3.predict(x_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacamos las métricas para ver si hay overfitting o unerfitting, para modificar la profundidad en función de estos resultados\n",
    "\n",
    "dt_results3 = metricas(y_test3, y_pred_test_esta3, y_train3, y_pred_train_esta3, \"Decission Tree Balanceada I\")\n",
    "dt_results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo primero que tenemos que hacer es definir un diccionario con los hiperparámetros que queremos modificar y los valores que queremos \n",
    "\n",
    "param3 = {\"max_depth\": [2,4, 6, 10, 12, 14], # teniendo en cuenta que teníamos overfitting tendremos que reducir la profundidad del modelo, la nuestra anterior era de 17. Bajaremos mucho este valor ya que teníamos un overfitting muy claro\n",
    "        \"max_features\": [1,2,3,4],# calculamos en celdas anteriores, probaremos a hacer el modelo como una variable, 2, 3 y 4. Ponemos como límite el 4 ya que es el resultado de la raiz cuadrada. \n",
    "        # estos dos hiperparámetros son más difíciles de definir, pero usualmente se suelen elegir los siguientes valores\n",
    "        \"min_samples_split\": [10, 50, 100],\n",
    "        \"min_samples_leaf\": [10,50,100]} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# una vez creado el diccionario iniciaremos el modelo con GridSearch\n",
    "\n",
    "gs3 = GridSearchCV(\n",
    "            estimator=DecisionTreeClassifier(random_state= 42), # tipo de modelo que queremos hacer\n",
    "            param_grid= param3, # que hiperparámetros queremos que testee\n",
    "            cv=10, # crossvalidation que aprendimos en la lección de regresión lineal intro. \n",
    "            verbose=-1) # para que no nos printee ningún mensaje en pantalla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustamos el modelo que acabamos de definir en el GridSearch\n",
    "\n",
    "gs3.fit(x_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# este método nos esta diciendo que el mejor modelo es aquel que tiene una profundidad de 6, que usa 4 variables predictoras para construir el modelo y que tiene  un min_samples_leaf y un min_samples_split de 10. \n",
    "mejor_modelo3 = gs3.best_estimator_\n",
    "mejor_modelo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veamos ahora que pinta tiene nuestro árbol\n",
    "\n",
    "fig = plt.figure(figsize=(40, 20))\n",
    "tree.plot_tree(mejor_modelo3, feature_names=x_train3.columns, filled=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_esta3 = mejor_modelo3.predict(x_test1)\n",
    "y_pred_train_esta3 = mejor_modelo3.predict(x_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos  a juntar los dataframes de los resultados de los modelos para poder compararlos mejor\n",
    "\n",
    "df_decision_results = pd.concat([dt_results1, dt_results2], axis = 0)\n",
    "df_decision_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si recodáis, en la clase de métricas guardamos en un csv los resultados de las métricas del modelo\n",
    "# vamos a cargar ese csv para comparar todos los modelos que hemos hecho, y comparar cuál de ellos es el mejor\n",
    "\n",
    "df_logistic_results = pd.read_pickle(\"../data-log/04-df_metricas_resultados.pickle\")\n",
    "df_logistic_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenamos todos los resultados\n",
    "\n",
    "df_DT_LR_results3 = pd.concat([df_logistic_results, df_decision_results], axis = 0).reset_index(drop=True)\n",
    "df_DT_LR_results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizaremos si queremos borrar algun ode lso resultados\n",
    "#df_DT_LR_results.drop([0,1,4,5], axis = 0, inplace = True)\n",
    "#df_DT_LR_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pongamos un poco de color a nuestro dataframe para ver la comparación de los datos de una forma un poco más amigable. \n",
    "df_DT_LR_results3.style.background_gradient(cmap='seismic')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importancia de las predictoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# vamos a crearnos un dataframe \n",
    "importancia_predictores_esta = pd.DataFrame(\n",
    "                            {'predictor': x_train1.columns,\n",
    "                             'importancia': mejor_modelo.feature_importances_}\n",
    "                            )\n",
    "\n",
    "\n",
    "# ordenamos de mayor a menor los resultados\n",
    "importancia_predictores_esta.sort_values(by=[\"importancia\"], ascending=False, inplace = True)\n",
    "\n",
    "# printeamos los resultados\n",
    "print(\"Importancia de los predictores en el modelo\")\n",
    "print(\"-------------------------------------------\")\n",
    "importancia_predictores_esta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo primero que hacemos es crearnos un dataframe con los valores solo de adulto, es decir, la primera y antepenúltima fila\n",
    "adulto = importancia_predictores_esta.iloc[[2, -2]]\n",
    "adulto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos lo mismo para embarque\n",
    "embarque = importancia_predictores_esta.loc[[5,7]]\n",
    "embarque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y para maturity\n",
    "madurez = importancia_predictores_esta.loc[[8,9]]\n",
    "madurez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y por último para saber si viajaban solos o no\n",
    "# hacemos lo mismo para embarque\n",
    "solos = importancia_predictores_esta.loc[[12,13]]\n",
    "solos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos esas filas del dataframe donde tenemos los valores de importancia\n",
    "\n",
    "importancia_predictores_esta.drop(adulto.index, inplace = True)\n",
    "importancia_predictores_esta.drop(madurez.index, inplace = True)\n",
    "importancia_predictores_esta.drop(embarque.index, inplace = True)\n",
    "importancia_predictores_esta.drop(solos.index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancia_predictores_esta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nos creamos nuevas filas con el resultado de la suma\n",
    "\n",
    "importancia_predictores_esta.loc[5] =  [\"adult_male\", adulto[\"importancia\"].sum()]\n",
    "importancia_predictores_esta.loc[6] =  [\"maturity\", madurez[\"importancia\"].sum()]\n",
    "importancia_predictores_esta.loc[7] =  [\"embark\", embarque[\"importancia\"].sum()]\n",
    "importancia_predictores_esta.loc[8] =  [\"alone\", solos[\"importancia\"].sum()]\n",
    "\n",
    "# ordenamos el df\n",
    "\n",
    "importancia_predictores_esta.sort_values(by = \"importancia\", ascending = False, inplace = True)\n",
    "importancia_predictores_esta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# por último ploteamos los resultados para verlo de una forma más amigable. \n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x = \"importancia\", y = \"predictor\", data = importancia_predictores_esta, palette=\"viridis\");\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7 (default, Sep 16 2021, 13:09:58) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8e782a3a92a384869fb83a8974812ed4d4d199ed3e8c8704ecd8a7536d7fad4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
