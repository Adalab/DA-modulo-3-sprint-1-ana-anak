{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Gráficos\n",
    "# ------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelado y evaluación\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score , cohen_kappa_score, roc_curve,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Configuración warnings\n",
    "# ------------------------------------------------------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair Programming Decision Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ana Gonzalez y Ana Campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cod_noest = pd.read_pickle(\"../data-log/02-df_codifcadas_no_estandarizadas.pickle\")\n",
    "df_cod_noest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cod_esta = pd.read_pickle(\"../data-log/02-df_estandarizadas_codificadas.pickle\")\n",
    "df_cod_esta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal = pd.read_pickle(\"../data-log/02-bal_est_cod.pickle\")\n",
    "df_bal.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Empezamos con codificadas, no estandarizadas, no balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos en X e y\n",
    "\n",
    "X1 = df_cod_noest.drop(\"survived\", axis = 1)\n",
    "y1 = df_cod_noest[\"survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos en train y test\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos el objeto del modelo, al igual que hacíamos en la regresión lineal\n",
    "arbol = DecisionTreeClassifier(random_state =0)\n",
    "\n",
    "# ajustamos el modelo, igual que en la regresión lienal. \n",
    "arbol.fit(x_train1, y_train1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "tree.plot_tree(arbol, feature_names = x_train1.columns, filled = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max features. Como vemos, debemos poner en nuestro modelo una profudidad máxima de 4. \n",
    "\n",
    "max_features = np.sqrt(len(x_train1.columns))\n",
    "max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# max depth\n",
    "\n",
    "print(arbol.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos las predicciones sobre los dos set de datos el X_test y el X_train\n",
    "y_pred_test_esta = arbol.predict(x_test1)\n",
    "y_pred_train_esta = arbol.predict(x_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas(clases_reales_test, clases_predichas_test, clases_reales_train, clases_predichas_train, modelo):\n",
    "    \n",
    "    # para el test\n",
    "    accuracy_test = accuracy_score(clases_reales_test, clases_predichas_test)\n",
    "    precision_test = precision_score(clases_reales_test, clases_predichas_test)\n",
    "    recall_test = recall_score(clases_reales_test, clases_predichas_test)\n",
    "    f1_test = f1_score(clases_reales_test, clases_predichas_test)\n",
    "    kappa_test = cohen_kappa_score(clases_reales_test, clases_predichas_test)\n",
    "\n",
    "    # para el train\n",
    "    accuracy_train = accuracy_score(clases_reales_train, clases_predichas_train)\n",
    "    precision_train = precision_score(clases_reales_train, clases_predichas_train)\n",
    "    recall_train = recall_score(clases_reales_train, clases_predichas_train)\n",
    "    f1_train = f1_score(clases_reales_train, clases_predichas_train)\n",
    "    kappa_train = cohen_kappa_score(clases_reales_train, clases_predichas_train)\n",
    "    \n",
    "\n",
    "    \n",
    "    df = pd.DataFrame({\"accuracy\": [accuracy_test, accuracy_train], \n",
    "                       \"precision\": [precision_test, precision_train],\n",
    "                       \"recall\": [recall_test, recall_train], \n",
    "                       \"f1\": [f1_test, f1_train],\n",
    "                       \"kapppa\": [kappa_test, kappa_train],\n",
    "                       \"set\": [\"test\", \"train\"]})\n",
    "    \n",
    "    df[\"modelo\"] = modelo\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacamos las métricas para ver si hay overfitting o unerfitting, para modificar la profundidad en función de estos resultados\n",
    "\n",
    "dt_results1 = metricas(y_test1, y_pred_test_esta, y_train1, y_pred_train_esta, \"Decission Tree Esta I\")\n",
    "dt_results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo primero que tenemos que hacer es definir un diccionario con los hiperparámetros que queremos modificar y los valores que queremos \n",
    "\n",
    "param = {\"max_depth\": [2,4, 6, 10, 12, 14], # teniendo en cuenta que teníamos overfitting tendremos que reducir la profundidad del modelo, la nuestra anterior era de 17. Bajaremos mucho este valor ya que teníamos un overfitting muy claro\n",
    "        \"max_features\": [1,2,3,4],# calculamos en celdas anteriores, probaremos a hacer el modelo como una variable, 2, 3 y 4. Ponemos como límite el 4 ya que es el resultado de la raiz cuadrada. \n",
    "        # estos dos hiperparámetros son más difíciles de definir, pero usualmente se suelen elegir los siguientes valores\n",
    "        \"min_samples_split\": [10, 50, 100],\n",
    "        \"min_samples_leaf\": [10,50,100]} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# una vez creado el diccionario iniciaremos el modelo con GridSearch\n",
    "\n",
    "gs = GridSearchCV(\n",
    "            estimator=DecisionTreeClassifier(random_state= 42), # tipo de modelo que queremos hacer\n",
    "            param_grid= param, # que hiperparámetros queremos que testee\n",
    "            cv=10, # crossvalidation que aprendimos en la lección de regresión lineal intro. \n",
    "            verbose=-1) # para que no nos printee ningún mensaje en pantalla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustamos el modelo que acabamos de definir en el GridSearch\n",
    "\n",
    "gs.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# este método nos esta diciendo que el mejor modelo es aquel que tiene una profundidad de 6, que usa 4 variables predictoras para construir el modelo y que tiene  un min_samples_leaf y un min_samples_split de 10. \n",
    "mejor_modelo = gs.best_estimator_\n",
    "mejor_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veamos ahora que pinta tiene nuestro árbol\n",
    "\n",
    "fig = plt.figure(figsize=(40, 20))\n",
    "tree.plot_tree(mejor_modelo, feature_names=x_train1.columns, filled=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_esta2 = mejor_modelo.predict(x_test1)\n",
    "y_pred_train_esta2 = mejor_modelo.predict(x_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_results2 = metricas(y_test1, y_pred_test_esta2, y_train1,  y_pred_train_esta2, \"Decision tree Esta II\")\n",
    "dt_results2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos  a juntar los dataframes de los resultados de los modelos para poder compararlos mejor\n",
    "\n",
    "df_decision_results = pd.concat([dt_results1, dt_results2], axis = 0)\n",
    "df_decision_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si recodáis, en la clase de métricas guardamos en un csv los resultados de las métricas del modelo\n",
    "# vamos a cargar ese csv para comparar todos los modelos que hemos hecho, y comparar cuál de ellos es el mejor\n",
    "\n",
    "df_logistic_results = pd.read_pickle(\"../data-log/04-df_metricas_resultados.pickle\")\n",
    "df_logistic_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenamos todos los resultados\n",
    "\n",
    "df_DT_LR_results = pd.concat([df_logistic_results, df_decision_results], axis = 0).reset_index(drop=True)\n",
    "df_DT_LR_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DT_LR_results.drop([0,1,4,5], axis = 0, inplace = True)\n",
    "df_DT_LR_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pongamos un poco de color a nuestro dataframe para ver la comparación de los datos de una forma un poco más amigable. \n",
    "df_DT_LR_results.style.background_gradient(cmap='seismic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ademas vamos a guardar este dataframe en un csv para \n",
    "\n",
    "df_DT_LR_results.to_csv(\"../files/resultados_titanic_LR_DT.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seguimos con codificadas, estandarizadas y no balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos en X e y\n",
    "\n",
    "X1 = df_cod_esta.drop(\"survived\", axis = 1)\n",
    "y1 = df_cod_esta[\"survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos en train y test\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos el objeto del modelo, al igual que hacíamos en la regresión lineal\n",
    "arbol = DecisionTreeClassifier(random_state =0)\n",
    "\n",
    "# ajustamos el modelo, igual que en la regresión lienal. \n",
    "arbol.fit(x_train1, y_train1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "tree.plot_tree(arbol, feature_names = x_train1.columns, filled = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max features. Como vemos, debemos poner en nuestro modelo una profudidad máxima de 4. \n",
    "\n",
    "max_features = np.sqrt(len(x_train1.columns))\n",
    "max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# max depth\n",
    "\n",
    "print(arbol.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos las predicciones sobre los dos set de datos el X_test y el X_train\n",
    "y_pred_test_esta = arbol.predict(x_test1)\n",
    "y_pred_train_esta = arbol.predict(x_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacamos las métricas para ver si hay overfitting o unerfitting, para modificar la profundidad en función de estos resultados\n",
    "\n",
    "dt_results1 = metricas(y_test1, y_pred_test_esta, y_train1, y_pred_train_esta, \"Decission Tree Esta I\")\n",
    "dt_results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo primero que tenemos que hacer es definir un diccionario con los hiperparámetros que queremos modificar y los valores que queremos \n",
    "\n",
    "param = {\"max_depth\": [2,4, 6, 10, 12, 14], # teniendo en cuenta que teníamos overfitting tendremos que reducir la profundidad del modelo, la nuestra anterior era de 17. Bajaremos mucho este valor ya que teníamos un overfitting muy claro\n",
    "        \"max_features\": [1,2,3,4],# calculamos en celdas anteriores, probaremos a hacer el modelo como una variable, 2, 3 y 4. Ponemos como límite el 4 ya que es el resultado de la raiz cuadrada. \n",
    "        # estos dos hiperparámetros son más difíciles de definir, pero usualmente se suelen elegir los siguientes valores\n",
    "        \"min_samples_split\": [10, 50, 100],\n",
    "        \"min_samples_leaf\": [10,50,100]} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# una vez creado el diccionario iniciaremos el modelo con GridSearch\n",
    "\n",
    "gs = GridSearchCV(\n",
    "            estimator=DecisionTreeClassifier(random_state= 42), # tipo de modelo que queremos hacer\n",
    "            param_grid= param, # que hiperparámetros queremos que testee\n",
    "            cv=10, # crossvalidation que aprendimos en la lección de regresión lineal intro. \n",
    "            verbose=-1) # para que no nos printee ningún mensaje en pantalla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustamos el modelo que acabamos de definir en el GridSearch\n",
    "\n",
    "gs.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# este método nos esta diciendo que el mejor modelo es aquel que tiene una profundidad de 6, que usa 4 variables predictoras para construir el modelo y que tiene  un min_samples_leaf y un min_samples_split de 10. \n",
    "mejor_modelo = gs.best_estimator_\n",
    "mejor_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veamos ahora que pinta tiene nuestro árbol\n",
    "\n",
    "fig = plt.figure(figsize=(40, 20))\n",
    "tree.plot_tree(mejor_modelo, feature_names=x_train1.columns, filled=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_esta2 = mejor_modelo.predict(x_test1)\n",
    "y_pred_train_esta2 = mejor_modelo.predict(x_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_results2 = metricas(y_test1, y_pred_test_esta2, y_train1,  y_pred_train_esta2, \"Decision tree Esta II\")\n",
    "dt_results2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos  a juntar los dataframes de los resultados de los modelos para poder compararlos mejor\n",
    "\n",
    "df_decision_results = pd.concat([dt_results1, dt_results2], axis = 0)\n",
    "df_decision_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si recodáis, en la clase de métricas guardamos en un csv los resultados de las métricas del modelo\n",
    "# vamos a cargar ese csv para comparar todos los modelos que hemos hecho, y comparar cuál de ellos es el mejor\n",
    "\n",
    "df_logistic_results = pd.read_pickle(\"../data-log/04-df_metricas_resultados.pickle\")\n",
    "df_logistic_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenamos todos los resultados\n",
    "\n",
    "df_DT_LR_results = pd.concat([df_logistic_results, df_decision_results], axis = 0).reset_index(drop=True)\n",
    "df_DT_LR_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DT_LR_results.drop([0,1,4,5], axis = 0, inplace = True)\n",
    "df_DT_LR_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pongamos un poco de color a nuestro dataframe para ver la comparación de los datos de una forma un poco más amigable. \n",
    "df_DT_LR_results.style.background_gradient(cmap='seismic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ademas vamos a guardar este dataframe en un csv para \n",
    "\n",
    "df_DT_LR_results.to_csv(\"../files/resultados_titanic_LR_DT.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Acabamos con balanceada, estandarizadas y codificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos en X e y\n",
    "\n",
    "X1 = df_bal.drop(\"survived\", axis = 1)\n",
    "y1 = df_bal[\"survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos en train y test\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos el objeto del modelo, al igual que hacíamos en la regresión lineal\n",
    "arbol = DecisionTreeClassifier(random_state =0)\n",
    "\n",
    "# ajustamos el modelo, igual que en la regresión lienal. \n",
    "arbol.fit(x_train1, y_train1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "tree.plot_tree(arbol, feature_names = x_train1.columns, filled = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max features. Como vemos, debemos poner en nuestro modelo una profudidad máxima de 4. \n",
    "\n",
    "max_features = np.sqrt(len(x_train1.columns))\n",
    "max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# max depth\n",
    "\n",
    "print(arbol.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos las predicciones sobre los dos set de datos el X_test y el X_train\n",
    "y_pred_test_esta = arbol.predict(x_test1)\n",
    "y_pred_train_esta = arbol.predict(x_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacamos las métricas para ver si hay overfitting o unerfitting, para modificar la profundidad en función de estos resultados\n",
    "\n",
    "dt_results1 = metricas(y_test1, y_pred_test_esta, y_train1, y_pred_train_esta, \"Decission Tree Esta I\")\n",
    "dt_results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo primero que tenemos que hacer es definir un diccionario con los hiperparámetros que queremos modificar y los valores que queremos \n",
    "\n",
    "param = {\"max_depth\": [2,4, 6, 10, 12, 14], # teniendo en cuenta que teníamos overfitting tendremos que reducir la profundidad del modelo, la nuestra anterior era de 17. Bajaremos mucho este valor ya que teníamos un overfitting muy claro\n",
    "        \"max_features\": [1,2,3,4],# calculamos en celdas anteriores, probaremos a hacer el modelo como una variable, 2, 3 y 4. Ponemos como límite el 4 ya que es el resultado de la raiz cuadrada. \n",
    "        # estos dos hiperparámetros son más difíciles de definir, pero usualmente se suelen elegir los siguientes valores\n",
    "        \"min_samples_split\": [10, 50, 100],\n",
    "        \"min_samples_leaf\": [10,50,100]} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustamos el modelo que acabamos de definir en el GridSearch\n",
    "\n",
    "gs.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# este método nos esta diciendo que el mejor modelo es aquel que tiene una profundidad de 6, que usa 4 variables predictoras para construir el modelo y que tiene  un min_samples_leaf y un min_samples_split de 10. \n",
    "mejor_modelo = gs.best_estimator_\n",
    "mejor_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veamos ahora que pinta tiene nuestro árbol\n",
    "\n",
    "fig = plt.figure(figsize=(40, 20))\n",
    "tree.plot_tree(mejor_modelo, feature_names=x_train1.columns, filled=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_esta2 = mejor_modelo.predict(x_test1)\n",
    "y_pred_train_esta2 = mejor_modelo.predict(x_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos  a juntar los dataframes de los resultados de los modelos para poder compararlos mejor\n",
    "\n",
    "df_decision_results = pd.concat([dt_results1, dt_results2], axis = 0)\n",
    "df_decision_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si recodáis, en la clase de métricas guardamos en un csv los resultados de las métricas del modelo\n",
    "# vamos a cargar ese csv para comparar todos los modelos que hemos hecho, y comparar cuál de ellos es el mejor\n",
    "\n",
    "df_logistic_results = pd.read_pickle(\"../data-log/04-df_metricas_resultados.pickle\")\n",
    "df_logistic_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenamos todos los resultados\n",
    "\n",
    "df_DT_LR_results = pd.concat([df_logistic_results, df_decision_results], axis = 0).reset_index(drop=True)\n",
    "df_DT_LR_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DT_LR_results.drop([0,1,4,5], axis = 0, inplace = True)\n",
    "df_DT_LR_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pongamos un poco de color a nuestro dataframe para ver la comparación de los datos de una forma un poco más amigable. \n",
    "df_DT_LR_results.style.background_gradient(cmap='seismic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# vamos a crearnos un dataframe \n",
    "importancia_predictores_esta = pd.DataFrame(\n",
    "                            {'predictor': x_train1.columns,\n",
    "                             'importancia': mejor_modelo.feature_importances_}\n",
    "                            )\n",
    "\n",
    "\n",
    "# ordenamos de mayor a menor los resultados\n",
    "importancia_predictores_esta.sort_values(by=[\"importancia\"], ascending=False, inplace = True)\n",
    "\n",
    "# printeamos los resultados\n",
    "print(\"Importancia de los predictores en el modelo\")\n",
    "print(\"-------------------------------------------\")\n",
    "importancia_predictores_esta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo primero que hacemos es crearnos un dataframe con los valores solo de adulto, es decir, la primera y antepenúltima fila\n",
    "adulto = importancia_predictores_esta.iloc[[2, -2]]\n",
    "adulto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos lo mismo para embarque\n",
    "embarque = importancia_predictores_esta.loc[[5,7]]\n",
    "embarque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y para maturity\n",
    "madurez = importancia_predictores_esta.loc[[8,9]]\n",
    "madurez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y por último para saber si viajaban solos o no\n",
    "# hacemos lo mismo para embarque\n",
    "solos = importancia_predictores_esta.loc[[12,13]]\n",
    "solos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos esas filas del dataframe donde tenemos los valores de importancia\n",
    "\n",
    "importancia_predictores_esta.drop(adulto.index, inplace = True)\n",
    "importancia_predictores_esta.drop(madurez.index, inplace = True)\n",
    "importancia_predictores_esta.drop(embarque.index, inplace = True)\n",
    "importancia_predictores_esta.drop(solos.index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancia_predictores_esta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nos creamos nuevas filas con el resultado de la suma\n",
    "\n",
    "importancia_predictores_esta.loc[5] =  [\"adult_male\", adulto[\"importancia\"].sum()]\n",
    "importancia_predictores_esta.loc[6] =  [\"maturity\", madurez[\"importancia\"].sum()]\n",
    "importancia_predictores_esta.loc[7] =  [\"embark\", embarque[\"importancia\"].sum()]\n",
    "importancia_predictores_esta.loc[8] =  [\"alone\", solos[\"importancia\"].sum()]\n",
    "\n",
    "# ordenamos el df\n",
    "\n",
    "importancia_predictores_esta.sort_values(by = \"importancia\", ascending = False, inplace = True)\n",
    "importancia_predictores_esta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# por último ploteamos los resultados para verlo de una forma más amigable. \n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x = \"importancia\", y = \"predictor\", data = importancia_predictores_esta, palette=\"viridis\");\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.9 (default, Mar 15 2022, 13:55:28) \n[GCC 8.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
